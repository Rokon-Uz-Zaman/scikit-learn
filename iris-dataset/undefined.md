# এস্টিমেটরের কাজের ধাপ

আগেই বলেছি "এস্টিমেটর" হচ্ছে সাইকিট-লার্নের ভাষায় মডেল। তার কাজের ধারা বুঝলে অনেকটাই আমরা বুঝে যাবো। 

এখন সাইকিট-লার্ন ‘এস্টিমেটর’ এপিআই এর কাজের ধারা বোঝার চেষ্টা করি। সিকোয়েন্স ধরে।

১ম ধাপ।

বেছে নিন একটা মডেল ক্লাস। এখানে আমরা বেছে নিয়েছি K-nearest neighbors ক্লাসিফায়ার। কেন? সবচেয়ে সোজা। খালি চোখে দেখা যায়। সেটা বলছি পরের চ্যাপ্টারে।

শুরুতেই সাইকিট লার্ন থেকে একটা জুতসই এস্টিমেটর ক্লাস ইমপোর্ট করতে হবে মডেলের ক্লাস হিসেবে। আমরা জানি, সাইকিট-লার্নে প্রতিটা মডেল ক্লাসকে রিপ্রেজেন্ট করা হয় পাইথন ক্লাস দিয়ে। আমাদের প্রতিটা মেশিন লার্নিং মডেল ইমপ্লিমেন্ট করতে হয় তাদের নিজস্ব ক্লাস ব্যবহার করে। এগুলোর নাম হচ্ছে এস্টিমেটর ক্লাস। আমাদের এখানে K-nearest neighbors ক্লাসিফিকেশন অ্যালগরিদমকে ইমপ্লিমেন্ট করা হচ্ছে KNeighborsClassifier ক্লাস দিয়ে। এটা আসছে আমাদের sklearn এর neighbors মডিউল থেকে।

from sklearn.neighbors import KNeighborsClassifier

২য় ধাপ।

মডেলের হাইপার-প্যারামিটার বেছে নিন। মনে আছে, আমরা কোন প্যারামিটার না দিলে কি হবে? আগেই বলেছি সাইকিট-লার্নের ডিফল্ট ভ্যালু নিয়ে নেবার কথা, ঠিক নয় কি? আমরা না দিলে সেটা নিজে থেকে নিয়ে নেবে। আমাদের এখানে টিউনিং প্যারামিটার হিসেবে আপাততঃ দিচ্ছি n\_neighbors=1, মানে একটা নেইবার। KNeighborsClassifier এর সবচেয়ে দরকারি প্যারামিটার হচ্ছে তার নেইবারের সংখ্যা।

আরেকটা কথা। এটাকে অনেকে বলেন “এস্টিমেটর”কে ইনস্ট্যান্সিয়েট করা। মানে মডেলের একটা ‘ইনস্ট্যান্স’ চালু করা। সাইকিট-লার্নে আমরা মডেলের ‘ইনস্ট্যান্স’ চালু করার সময় হাইপার-প্যারামিটারগুলোর ভ্যালুগুলোকে পাঠিয়ে দেই ওই মডেলে। একটা মডেলের ক্লাস কিন্তু ওই মডেলের ইনস্ট্যান্স নয়। এদুটো আলাদা জিনিস। আমরা যখন মডেল এর একটা ‘ইনস্ট্যান্স’ চালু করি, সেটা হাইপার-প্যারামিটারগুলো ‘স্টোর’ করে রাখে। আমরা এখনো মডেলকে কোন ডাটা দেখাইনি। সাইকিট-লার্ন এপিআই ইন্টারফেস কিন্তু ‘মডেলের বেছে নেয়া’র কাজ থেকে ডাটার ওপর মডেলের অ্যাপ্লিকেশনকে আলাদা করে রাখে। knn = KNeighborsClassifier\(n\_neighbors=1\)

আমাদেরকে মডেলকে ‘ইনস্ট্যান্সিয়েট’ \(মডেলের একটা ‘ইনস্ট্যান্স’ চালু করা\) করতে হবে একটা অবজেক্টে। এখানে অবজেক্টের নাম দিতে পারেন ইচ্ছেমতো। এখানে আমরা ব্যবহার করেছি knn, কারণ সবাই শুরুতে এধরণের নাম দেয়। চলুন দেখি অবজেক্টটা।

print\(knn\)

KNeighborsClassifier\(algorithm='auto', leaf\_size=30, metric='minkowski', metric\_params=None, n\_jobs=1, n\_neighbors=1, p=2, weights='uniform'\)

আমাদের knn অবজেক্ট তার ভেতর ট্রেনিং ডাটা থেকে যে মডেল তৈরি করবে সেটার অ্যালগরিদমকে রাখবে। এই অ্যালগরিদমই ব্যবহার হবে নতুন ডাটা প্রেডিকশন করতে। ট্রেনিং ডাটা থেকে যা জ্ঞান পাবে সেটাও স্টোর করবে সে।

৩য় ধাপ।

ডাটাকে সাজাই ফীচার ম্যাট্রিক্স এবং টার্গেট ভেক্টরের মতো করে।

এর আগে কি দেখেছি? সাইকিট-লার্ন ডাটা রিপ্রেজেন্টেশনে আমাদের দুই ডাইমেনশনের ফীচার ম্যাট্রিক্স আর এক ডাইমেশনের টার্গেট অ্যারে লাগে।

{% hint style="info" %}
\#ফিচার ম্যাট্রিক্সকে রাখছি 

"X" এ X = iris.data

\#টার্গেট ভেক্টরকে রাখা হচ্ছে "y" এ 

y = iris.target
{% endhint %}

৪র্থ ধাপ।

আমাদের মডেলে ডাটা “ফিট” করা।

ট্রেনিং সেট থেকে \(এখানে যেটা আমাদের পুরো ডাটা, ১৫০টা রেকর্ড\) মডেল তৈরি করতে আমরা “ফিট” মেথড কল করবো knn অবজেক্ট থেকে। কল করার সঙ্গে সঙ্গে সে দুটো জিনিসকে আর্গুমেন্ট হিসেবে নেয়। বলুন তো কোন দুটো জিনিস? ঠিক ধরেছেন একটা, ফিচার অ্যারে আর একটা টার্গেট ভেক্টর। সোজা কথায় আগের ধাপে বের করা বড় হাতের X আর ছোট হাতের y কে ‘ফিট’ কমান্ড আসলে ফিচার মেট্রিক্স আর টার্গেট ভেক্টরের মধ্যে সম্পর্কটা শিখিয়ে দেয়় মডেলকে। ফিট কমান্ডের আউটপুট দেখলেই বুঝবেন এই মেথডটা আসলে knn অবজেক্টকে রিটার্ন করে দিচ্ছে সঙ্গে সঙ্গে। পাশাপাশি এর ভেতরের ইন্টার্নাল কম্পিউটেশন করে নিচ্ছে যা ওই মডেল ডিপেন্ডেন্ট। Knn অবজেক্টকে রিটার্ন করার সাথে সাথে পুরো ক্লাসিফায়ার এর ‘স্ট্রিং রিপ্রেজেন্টেশন’ \(আউটপুট\) দিয়ে দিচ্ছে এখানে। সোজা কথায়, এই মডেলটা যত প্যারামিটার ব্যবহার করেছে, সেগুলো দেখিয়ে দিয়েছে এখানে। পাশাপাশি সাইকিট লার্নের কনভেনশন অনুযায়ী এই ফিট \(\) প্রসেসে মডেল যা শিখছে

৫ম ধাপ।

অজানা, নতুন ডাটার লেবেল প্রেডিক্ট করা। নতুন ডাটাকে বলছি “আউট অফ স্যাম্পল” ডাটা। মডেল ট্রেনিং থেকে শিখে প্রেডিক্ট করে নতুন ডাটাকে একটা লেবেল দিয়ে। আউটপুট দিচ্ছে একটা নামপাই অ্যারে। 

