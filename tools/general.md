# মডেলের জেনারেলাইজেশন, ওভার-ফিটিং এবং আন্ডার-ফিটিং

সুপারভাইজড লার্নিংয়ে আমরা ট্রেনিং ডেটার ওপর যখন মডেল তৈরি করি, তখন চেষ্টা করা হয় যাতে মডেলটা ঠিকমতো প্রেডিকশন করতে পারে নতুন এবং অজানা ডাটার ওপর। আমরা ধারণা করি আমাদের নতুন অজানা ডেটার একই বৈশিষ্ট্য থাকবে যেই বৈশিষ্ট্যগুলোকে ট্রেনিং সেট থেকে পেয়েছিলাম। আমাদের মডেল যদি সঠিক প্রেডিকশন করতে পারে অজানা ডাটার ওপর - তখন আমরা বলি আমাদের মডেলটা ঠিকমতো “জেনারেলাইজ” করা হয়েছে ট্রেনিং সেট থেকে টেস্ট সেটে। আমরা এমন একটা মডেল তৈরি করতে চাই যেটার প্রেডিকশন নতুন যেকোনো ধরনের অজানা ডেটার ওপর ঠিকভাবে “জেনারালাইজ” করতে পারে। শুধুমাত্র ওই ট্রেনিং ডেটাকে ঘিরে নয়।

একটা জিনিস দেখা গেছে, আমরা যখন মডেল তৈরি করি তখন তার প্যারামিটারগুলো এমনভাবে টিউনিং করি যাতে সেটা ঠিকমতো প্রেডিকশন করতে পারে ট্রেনিং সেটের উপর। তাহলে অজানা ডেটার ওপর ভালো করবে কিভাবে? আমাদের ট্রেনিং এবং টেস্ট ডেটাসেটের ভেতরে বেশি মাত্রায় যদি একই ধরনের বৈশিষ্ট্য থাকে, তখন আমরা ধারণা করি যে আমাদের মডেলটা ঠিকমতো কাজ করবে টেস্ট সেটের উপর। তবে যে জিনিসটা আমরা দেখেছি, ট্রেনিং সেট থেকে সবগুলো বৈশিষ্ট্য নিয়ে আমরা মডেল তৈরি করলে অজানা ডেটার জন্য ওপেন না থেকে বেশি মাত্রায় ‘ট্রেনিং ডেটা সেন্ট্রিক’ হয়ে যায়। তখন অজানা ডেটার ভেতরে সামান্য একটা বৈশিষ্ট্য পাল্টে গেলে মডেল ঠিকমতো প্রেডিক্ট করতে পারেনা। সে কারণে আমরা কখনোই ট্রেনিং ডেটা থেকে প্রতিটা বৈশিষ্ট্যকে নিয়ে এমন মডেল তৈরি করব না যাতে সেটা বেশি ‘কমপ্লেক্স’ হয়। বেশি ‘কমপ্লেক্স’ মডেল হলে সেটা অজানা ডেটার জন্য ওপেন থাকবে না। মানে ‘জেনারালাইজ’ হবে না। এদিকে আবার বেশি সিম্পল মডেল হলে সেট ‘আন্ডার-ফিটিং’ হতে পারে। এর অর্থ হচ্ছে ট্রেনিং ডেটা থেকে অনেক দরকারি বৈশিষ্ট্য বাদ পড়ে গেছে বলে নতুন ডেটাকে ঠিকমতো প্রেডিক্ট করতে পারছে না। আবার বেশি বৈশিষ্ট্যকে ট্রেনিং দেয়ার মতো করে নিয়ে আসলে মডেলটা শুধুমাত্র ওই ট্রেনিং ডেটা সেটের জন্য ‘অসাধারণ’ভাবে কাজ করবে তবে নতুন অজানা ডেটাতে খারাপ করবে। আমরা সেটাকে বলি ‘ওভার-ফিটিং’।

আমাদের মডেল যতো বেশি কমপ্লেক্স হবে, সেটা ততো বেশি ভালো করে ট্রেনিং ডেটা প্রেডিক্ট করতে পারবে। আমরা কী সেটা চাই? না সেটা চাইনা। আমরা চাই মডেল ভালো করে কাজ করে অজানা ডেটার ওপর। সেকারণে টেস্ট ডেটার জন্য ওপেন করতে হবে মডেলকে। আমরা যদি ট্রেনিং এর প্রতিটা রেকর্ড ধরে ধরে অ্যানালাইসিস করি, তাহলে সেটা ট্রেনিং ডেটাকে ঠিকমতো প্রেডিক্ট করতে পারবে তবে, অজানা ডেটা নিয়ে প্রশ্ন থাকবে। সেটাকে 'জেনারেলাইজ' করা হলো না। আমি নিজে দেখেছি ট্রেনিং ডেটাতে মডেলের অ্যাক্যুরেসি ৯৬%, টেস্টে সেটা কমে এসেছে ৮০%। মানে প্রশ্ন ফাঁস। ট্রেনিং ডেটাকে \(পরীক্ষার প্রশ্ন\) মুখস্ত করেছে, আর বাকি বই পড়েনি।   

আমাদের মডেল নতুন অজানা ডেটাকে নিয়ে কিভাবে কাজ করবে সেটা জানার জন্য ব্যবহার করি ‘টেস্ট সেট’। কারণ, প্রাসঙ্গিকভাবে অজানা ডেটার ব্যাপারে আমাদের জানার স্কোপ নেই আগে থেকে। সে কারণে টেস্ট ডাটা সেটে ভালোভাবে কাজ করতে হলে আমাদের মডেলকে কিছুটা ওপেন হতে হবে। আর সেকারণে আমরা ট্রেনিং ডেটা থেকে সবগুলো বৈশিষ্ট্য ব্যবহার করব না। সেটা করলে ‘ওভার-ফিটিং’ হবে। মানে, ট্রেনিং ডেটার ওপরে খুব ভালোভাবে কাজ করবে কিন্তু টেস্ট ডেটা সেটে কম ‘অ্যাক্যুরেসি’ পাবে। আবার ট্রেনিং ডেটা সেট থেকে অল্প বৈশিষ্ট্য নেব না যাতে মডেলটা বেশি ‘সিম্প্লিফাইড’ হয়। আমার অভিজ্ঞতা বলে এখানে একটা ‘রাইট ব্যালেন্স’ দরকার। নিচের ছবিটা দেখি একটু। 

![&#x9AE;&#x9A1;&#x9C7;&#x9B2;&#x9C7;&#x9B0; &#x99C;&#x9C7;&#x9A8;&#x9BE;&#x9B0;&#x9C7;&#x9B2;&#x9BE;&#x987;&#x99C;&#x9C7;&#x9B6;&#x9A8;, &#x993;&#x9AD;&#x9BE;&#x9B0;-&#x9AB;&#x9BF;&#x99F;&#x9BF;&#x982; &#x98F;&#x9AC;&#x982; &#x986;&#x9A8;&#x9CD;&#x9A1;&#x9BE;&#x9B0;-&#x9AB;&#x9BF;&#x99F;&#x9BF;&#x982;](../.gitbook/assets/general.png)



সে কারণে যতো বেশি ট্রেনিং ডেটা থাকবে ততো মডেলকে ‘জেনারালাইজ’ মানে ‘ওপেন’ করা যাবে যাতে যেকোন অজানা ডেটার সাথে ভালো কাজ করতে পারে। বেশি ডেটা থাকলে মডেল একটু ‘কমপ্লেক্স’ হবে তবে সেটা ‘ওভার অল’ মডেলের জন্য খুব ভালো কাজ করবে। ব্যাপারটা যতো গুড় ততো মিষ্টির মতো। বেশি ট্রেনিং ডেটা মানে বেশি ‘অ্যাক্যুরেসি’। তবে আমাদের বোঝার সুবিধার্থে আমি ‘ফিক্সড সাইজ’ এর ডেটা নিয়ে কাজ করছি।

